{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from thefuzz import fuzz, process\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating datasets...\n",
      "Creating variations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 622/622 [00:00<00:00, 617188.81it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to generate name variations\n",
    "def create_name_variation(name):\n",
    "    variations = []\n",
    "    # Original name\n",
    "    first, last = name.split(' ')\n",
    "    \n",
    "    # Common variations\n",
    "    variations.extend([\n",
    "        f\"{first}{last}\",  # No space\n",
    "        f\"{first.lower()} {last}\",  # Lower first name\n",
    "        f\"{first} {last.lower()}\",  # Lower last name\n",
    "        first[0] + \". \" + last,  # Initial for first name\n",
    "        first.replace('a', 'e'),  # Common vowel swap\n",
    "        last.replace('o', 'ou'),  # Common addition\n",
    "        first[:-1] + \" \" + last,  # Missing last letter in first name\n",
    "        first + \" \" + last + \"n\",  # Extra n at end\n",
    "        first.replace('ch', 'k'),  # Phonetic variation\n",
    "        first + \" \" + last.replace('s', 'z')  # s/z swap\n",
    "    ])\n",
    "    \n",
    "    return variations\n",
    "\n",
    "# Generate large original dataset\n",
    "def generate_names(n):\n",
    "    first_names = [\n",
    "        \"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Richard\", \"Joseph\",\n",
    "        \"Thomas\", \"Charles\", \"Christopher\", \"Daniel\", \"Matthew\", \"Anthony\", \"Donald\",\n",
    "        \"Mary\", \"Patricia\", \"Jennifer\", \"Linda\", \"Elizabeth\", \"Barbara\", \"Susan\",\n",
    "        \"Jessica\", \"Sarah\", \"Karen\", \"Nancy\", \"Lisa\", \"Margaret\", \"Sandra\", \"Ashley\"\n",
    "    ]\n",
    "    \n",
    "    last_names = [\n",
    "        \"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\",\n",
    "        \"Rodriguez\", \"Martinez\", \"Hernandez\", \"Lopez\", \"Gonzalez\", \"Wilson\", \"Anderson\",\n",
    "        \"Thomas\", \"Taylor\", \"Moore\", \"Jackson\", \"Martin\", \"Lee\", \"Thompson\", \"White\",\n",
    "        \"Harris\", \"Clark\", \"Lewis\", \"Robinson\", \"Walker\", \"Hall\", \"Young\"\n",
    "    ]\n",
    "    \n",
    "    names = []\n",
    "    for _ in range(n):\n",
    "        first = random.choice(first_names)\n",
    "        last = random.choice(last_names)\n",
    "        names.append(f\"{first} {last}\")\n",
    "    \n",
    "    return list(set(names))  # Remove duplicates\n",
    "\n",
    "# Function to compare names using different fuzzy matching methods\n",
    "def compare_names(name1, name2):\n",
    "    ratio = fuzz.ratio(name1, name2)\n",
    "    partial_ratio = fuzz.partial_ratio(name1, name2)\n",
    "    token_sort_ratio = fuzz.token_sort_ratio(name1, name2)\n",
    "    token_set_ratio = fuzz.token_set_ratio(name1, name2)\n",
    "    \n",
    "    return {\n",
    "        'ratio': ratio,\n",
    "        'partial_ratio': partial_ratio,\n",
    "        'token_sort_ratio': token_sort_ratio,\n",
    "        'token_set_ratio': token_set_ratio\n",
    "    }\n",
    "\n",
    "# Generate datasets\n",
    "print(\"Generating datasets...\")\n",
    "original_names = generate_names(1000)\n",
    "variant_names = []\n",
    "\n",
    "# Create variations\n",
    "print(\"Creating variations...\")\n",
    "for name in tqdm(original_names):\n",
    "    variations = create_name_variation(name)\n",
    "    variant_names.extend(variations)\n",
    "\n",
    "# Add some completely different names to variant dataset\n",
    "extra_names = generate_names(200)\n",
    "variant_names.extend(extra_names)\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_original = pd.DataFrame(original_names, columns=['name'])\n",
    "df_variants = pd.DataFrame(variant_names, columns=['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fuzzy matching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 622/622 [00:08<00:00, 76.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching Results:\n",
      "Total original names: 622\n",
      "Total variant names: 6404\n",
      "Total matches found: 1866\n",
      "\n",
      "Example matches (sorted by token_set_score):\n",
      "         original_name      matched_name  token_set_score  ratio_score  \\\n",
      "1865        Sandra Lee            Sandra              100           75   \n",
      "0         Daniel Jones      daniel Jones              100           92   \n",
      "1         Daniel Jones      Daniel jones              100           92   \n",
      "2         Daniel Jones            Daniel              100           67   \n",
      "3     Jessica Martinez  jessica Martinez              100           94   \n",
      "4     Jessica Martinez  Jessica martinez              100           94   \n",
      "5     Jessica Martinez          Martinez              100           67   \n",
      "6             John Lee          john Lee              100           88   \n",
      "7             John Lee          John lee              100           88   \n",
      "8             John Lee              John              100           67   \n",
      "\n",
      "      partial_ratio_score  token_sort_score  \n",
      "1865                  100                75  \n",
      "0                      96               100  \n",
      "1                      92               100  \n",
      "2                     100                67  \n",
      "3                      97               100  \n",
      "4                      94               100  \n",
      "5                     100                67  \n",
      "6                      93               100  \n",
      "7                      88               100  \n",
      "8                     100                67  \n",
      "\n",
      "Score distribution:\n",
      "       token_set_score  ratio_score  partial_ratio_score  token_sort_score\n",
      "count      1866.000000  1866.000000          1866.000000       1866.000000\n",
      "mean         99.983387    64.639871            99.572347         65.200429\n",
      "std           0.227452    11.441939             1.659603         12.871129\n",
      "min          96.000000    33.000000            76.000000         33.000000\n",
      "25%         100.000000    57.000000           100.000000         57.000000\n",
      "50%         100.000000    63.000000           100.000000         63.000000\n",
      "75%         100.000000    70.000000           100.000000         70.000000\n",
      "max         100.000000   100.000000           100.000000        100.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform fuzzy matching\n",
    "def perform_fuzzy_matching(df_original, df_variants, threshold=80):\n",
    "    matches = []\n",
    "    print(\"Performing fuzzy matching...\")\n",
    "    \n",
    "    for original_name in tqdm(df_original['name']):\n",
    "        # Get best matches using token_set_ratio (often best for names)\n",
    "        best_matches = process.extractBests(\n",
    "            original_name, \n",
    "            df_variants['name'].tolist(),\n",
    "            scorer=fuzz.token_set_ratio,\n",
    "            score_cutoff=threshold,\n",
    "            limit=3\n",
    "        )\n",
    "        \n",
    "        for match, score in best_matches:\n",
    "            # Get detailed comparison scores\n",
    "            detailed_scores = compare_names(original_name, match)\n",
    "            matches.append({\n",
    "                'original_name': original_name,\n",
    "                'matched_name': match,\n",
    "                'token_set_score': score,\n",
    "                'ratio_score': detailed_scores['ratio'],\n",
    "                'partial_ratio_score': detailed_scores['partial_ratio'],\n",
    "                'token_sort_score': detailed_scores['token_sort_ratio']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "# Perform the matching\n",
    "results = perform_fuzzy_matching(df_original, df_variants)\n",
    "\n",
    "# Analysis and visualization\n",
    "print(\"\\nMatching Results:\")\n",
    "print(f\"Total original names: {len(df_original)}\")\n",
    "print(f\"Total variant names: {len(df_variants)}\")\n",
    "print(f\"Total matches found: {len(results)}\")\n",
    "\n",
    "# Display some example matches\n",
    "print(\"\\nExample matches (sorted by token_set_score):\")\n",
    "print(results.sort_values('token_set_score', ascending=False).head(10))\n",
    "\n",
    "# Score distribution analysis\n",
    "print(\"\\nScore distribution:\")\n",
    "print(results[['token_set_score', 'ratio_score', \n",
    "              'partial_ratio_score', 'token_sort_score']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Sekinal/fuzzyclass/tree/master\n",
    "# https://github.com/Sekinal/fuzzyclass/issues/1\n",
    "# average the 3 scores and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         original_name      matched_name  token_set_score  ratio_score  \\\n",
      "1865        Sandra Lee            Sandra              100           75   \n",
      "0         Daniel Jones      daniel Jones              100           92   \n",
      "1         Daniel Jones      Daniel jones              100           92   \n",
      "2         Daniel Jones            Daniel              100           67   \n",
      "3     Jessica Martinez  jessica Martinez              100           94   \n",
      "4     Jessica Martinez  Jessica martinez              100           94   \n",
      "5     Jessica Martinez          Martinez              100           67   \n",
      "6             John Lee          john Lee              100           88   \n",
      "7             John Lee          John lee              100           88   \n",
      "8             John Lee              John              100           67   \n",
      "\n",
      "      partial_ratio_score  token_sort_score  \n",
      "1865                  100                75  \n",
      "0                      96               100  \n",
      "1                      92               100  \n",
      "2                     100                67  \n",
      "3                      97               100  \n",
      "4                      94               100  \n",
      "5                     100                67  \n",
      "6                      93               100  \n",
      "7                      88               100  \n",
      "8                     100                67  \n"
     ]
    }
   ],
   "source": [
    "print(results.sort_values('token_set_score', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column for average\n",
    "\n",
    "results['avg_score'] = (results['token_set_score'] + results['ratio_score'] + results['partial_ratio_score'] + results['token_sort_score']) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         original_name matched_name  token_set_score  ratio_score  \\\n",
      "906   Anthony Anderson      Anthony              100           61   \n",
      "1824     Anthony Brown      Anthony              100           70   \n",
      "519      Anthony Clark      Anthony              100           70   \n",
      "97       Anthony Davis      Anthony              100           70   \n",
      "224     Anthony Harris      Anthony              100           67   \n",
      "...                ...          ...              ...          ...   \n",
      "235     William Walker      William              100           67   \n",
      "952      William White      William              100           70   \n",
      "1165  William Williams     Williams              100           67   \n",
      "1677    William Wilson      William              100           67   \n",
      "1797     William Young      William              100           70   \n",
      "\n",
      "      partial_ratio_score  token_sort_score  avg_score  \n",
      "906                   100                61       80.5  \n",
      "1824                  100                70       85.0  \n",
      "519                   100                70       85.0  \n",
      "97                    100                70       85.0  \n",
      "224                   100                67       83.5  \n",
      "...                   ...               ...        ...  \n",
      "235                   100                67       83.5  \n",
      "952                   100                70       85.0  \n",
      "1165                  100                67       83.5  \n",
      "1677                  100                67       83.5  \n",
      "1797                  100                70       85.0  \n",
      "\n",
      "[622 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "best_matches = results.loc[results.groupby('original_name')['avg_score'].idxmax()]\n",
    "\n",
    "print(best_matches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       original_name    matched_name  token_set_score  ratio_score  \\\n",
      "1793   Richard Young   Richard Young              100          100   \n",
      "374   Richard Wilson  Richard Wilson              100          100   \n",
      "1805   Richard Brown   Richard Brown              100          100   \n",
      "1091   Richard Lopez   Richard Lopez              100          100   \n",
      "917    Michael Brown   Michael Brown              100          100   \n",
      "...              ...             ...              ...          ...   \n",
      "1128   Lisa Anderson            Lisa              100           47   \n",
      "309       Robert Lee             Lee              100           46   \n",
      "984   Lisa Rodriguez            Lisa              100           44   \n",
      "1491  Mary Rodriguez            Mary              100           44   \n",
      "657      Michael Lee             Lee              100           43   \n",
      "\n",
      "      partial_ratio_score  token_sort_score  avg_score  \n",
      "1793                  100               100      100.0  \n",
      "374                   100               100      100.0  \n",
      "1805                  100               100      100.0  \n",
      "1091                  100               100      100.0  \n",
      "917                   100               100      100.0  \n",
      "...                   ...               ...        ...  \n",
      "1128                  100                47       73.5  \n",
      "309                   100                46       73.0  \n",
      "984                   100                44       72.0  \n",
      "1491                  100                44       72.0  \n",
      "657                   100                43       71.5  \n",
      "\n",
      "[622 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(best_matches.sort_values('avg_score', ascending=False).head(700))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
